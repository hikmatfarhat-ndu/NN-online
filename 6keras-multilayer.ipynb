{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras-multilayer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.8 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "ffa8138a954375a0eba8eca80543292cc4faeae39ef0340fcb1267261a1ca77f"
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hikmatfarhat-ndu/NN-online/blob/main/6keras-multilayer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJZCA1yWDMPU"
      },
      "source": [
        "# Multilayer Feedforward Using Keras Functional API\n",
        "\n",
        "\n",
        "In this exercise we train our keras model on the MNIST dataset again. But this time we use keras instead and specifically we use the keras functional API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wxn309X9dUHT"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input,Dense,Flatten,Conv2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-R5raOpLdkRs"
      },
      "source": [
        "def load_dataset():\n",
        "  # tensorflow assumes the input and output are row vectors\n",
        "  # where as in our implementation we use them as column vectors\n",
        "    tr,te=tf.keras.datasets.mnist.load_data()\n",
        "    X=tr[0].astype(\"float32\")/255\n",
        "    Y=tr[1]\n",
        "    Y=Y.reshape(1,len(Y))\n",
        "    V=np.zeros((10,Y.shape[1]))\n",
        "    for j in range(Y.shape[1]):\n",
        "        V[Y[0,j],j]=1\n",
        "        \n",
        "    Y=V.astype(\"float32\")\n",
        "    test_data=te[0].astype(\"float32\")/255\n",
        "    test_labels=te[1].astype(\"float32\")\n",
        "    test_labels=test_labels.reshape(1,len(test_labels))\n",
        "    return X,Y.T,test_data,test_labels.T\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HSeTuaKXAY1"
      },
      "source": [
        "### Rectified Linear Unit \n",
        "In this exercise we use the ReLU activation function for the inner layers. The sigmoid, and similar, activation functions suffer from the __vanishing gradient__ problem especially for deep networks. This is due to the saturation of the sigmoid where for large values the derivative approaches zero. In multilayer networks, we saw that derivative at a given layer is multiplied by the derivative of the next (backpropagation) which makes learning harder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIbIZe46XAY1"
      },
      "source": [
        "def relu(x):\n",
        "  return x*(x>0)\n",
        "relu_x=np.array([i for i in range(-5,10)])\n",
        "relu_y=relu(relu_x)\n",
        "fig,ax=plt.subplots()\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_xlim(-5,10)\n",
        "ax.set_ylim(0,10)\n",
        "ax.plot(relu_x,relu_y)\n",
        "plt.xticks(range(-5,11,1))\n",
        "plt.yticks(np.arange(0,11,1))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvEmfFo74Gqe"
      },
      "source": [
        "## Keras Functional API\n",
        "\n",
        "Even though our model for this exercise is also __Sequential__ we will introduce the more flexible __functional__ API.\n",
        "If we use the __Sequential__ model then our model would be\n",
        "```\n",
        "model= Sequential()\n",
        "model.add(Input(shape=(784,)))\n",
        "model.add(Dense(128,activation=\"relu\"))\n",
        "model.add(Dense(64,activation=\"relu\"))\n",
        "model.add(Dense(10,activation=\"softmax\"))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rjOERSpCEvE"
      },
      "source": [
        "### Equivalent model using the functional API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2TO1rtdfxFj"
      },
      "source": [
        "input=tf.keras.layers.Input(shape=(784,))\n",
        "first_dense=tf.keras.layers.Dense(128,activation=\"relu\")(input)\n",
        "second_dense=tf.keras.layers.Dense(64,activation=\"relu\")(first_dense)\n",
        "last_layer=tf.keras.layers.Dense(10,activation=\"softmax\")(second_dense)\n",
        "\n",
        "model=tf.keras.Model(inputs=input,outputs=last_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ-fcE1gf6Di"
      },
      "source": [
        "X,Y,test_data,test_labels = load_dataset()\n",
        "\n",
        "X=X.reshape(60000,784)\n",
        "test_data=test_data.reshape(10000,784)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x2me_zYCYmf"
      },
      "source": [
        "### Using the function call instead of names\n",
        "\n",
        "__NOTE__: the labels are in one-hot encoding. If they were not then we use\n",
        "```\n",
        "SparseCategoricalCrossentropy instead of CategoricalCrossentropy\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO72TEvcgNmK"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),  # Optimizer\n",
        "    # Loss function to minimize\n",
        "    #loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    # List of metrics to monitor\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTNNOES8ESPs"
      },
      "source": [
        "### Saving intermediate computations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnvNgHpteZEd"
      },
      "source": [
        "batch_size=64\n",
        "\n",
        "filepath=\"checkpoints/cp-{epoch}.ckpt\"\n",
        "cb=tf.keras.callbacks.ModelCheckpoint(filepath,save_weights_only=True,save_freq='epoch',verbose=1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnmeq1DHC1uc"
      },
      "source": [
        "### Fit model to data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3fi-5KogPCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d63cd75-b23f-42f6-9610-a872175add76"
      },
      "source": [
        "history = model.fit(X,Y,batch_size=batch_size,epochs=11,callbacks=[cb],verbose=0)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: saving model to checkpoints/cp-1.ckpt\n",
            "\n",
            "Epoch 00002: saving model to checkpoints/cp-2.ckpt\n",
            "\n",
            "Epoch 00003: saving model to checkpoints/cp-3.ckpt\n",
            "\n",
            "Epoch 00004: saving model to checkpoints/cp-4.ckpt\n",
            "\n",
            "Epoch 00005: saving model to checkpoints/cp-5.ckpt\n",
            "\n",
            "Epoch 00006: saving model to checkpoints/cp-6.ckpt\n",
            "\n",
            "Epoch 00007: saving model to checkpoints/cp-7.ckpt\n",
            "\n",
            "Epoch 00008: saving model to checkpoints/cp-8.ckpt\n",
            "\n",
            "Epoch 00009: saving model to checkpoints/cp-9.ckpt\n",
            "\n",
            "Epoch 00010: saving model to checkpoints/cp-10.ckpt\n",
            "\n",
            "Epoch 00011: saving model to checkpoints/cp-11.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZfcqdEFGC7c"
      },
      "source": [
        "### List the content of the directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG9Bov4tfc4p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9400b4e6-d85a-41c1-8d51-7de8c8c9f636"
      },
      "source": [
        "!ls  -lR /content/checkpoints"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/checkpoints:\n",
            "total 14216\n",
            "-rw-r--r-- 1 root root      77 Nov 21 05:07 checkpoint\n",
            "-rw-r--r-- 1 root root 1315485 Nov 21 05:06 cp-10.ckpt.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root    1634 Nov 21 05:06 cp-10.ckpt.index\n",
            "-rw-r--r-- 1 root root 1315485 Nov 21 05:07 cp-11.ckpt.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root    1634 Nov 21 05:07 cp-11.ckpt.index\n",
            "-rw-r--r-- 1 root root 1315485 Nov 21 05:06 cp-1.ckpt.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root    1634 Nov 21 05:06 cp-1.ckpt.index\n",
            "-rw-r--r-- 1 root root 1315485 Nov 21 05:06 cp-2.ckpt.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root    1634 Nov 21 05:06 cp-2.ckpt.index\n",
            "-rw-r--r-- 1 root root 1315485 Nov 21 05:06 cp-3.ckpt.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root    1634 Nov 21 05:06 cp-3.ckpt.index\n",
            "-rw-r--r-- 1 root root 1315485 Nov 21 05:06 cp-4.ckpt.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root    1634 Nov 21 05:06 cp-4.ckpt.index\n",
            "-rw-r--r-- 1 root root 1315485 Nov 21 05:06 cp-5.ckpt.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root    1634 Nov 21 05:06 cp-5.ckpt.index\n",
            "-rw-r--r-- 1 root root 1315485 Nov 21 05:06 cp-6.ckpt.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root    1634 Nov 21 05:06 cp-6.ckpt.index\n",
            "-rw-r--r-- 1 root root 1315485 Nov 21 05:06 cp-7.ckpt.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root    1634 Nov 21 05:06 cp-7.ckpt.index\n",
            "-rw-r--r-- 1 root root 1315485 Nov 21 05:06 cp-8.ckpt.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root    1634 Nov 21 05:06 cp-8.ckpt.index\n",
            "-rw-r--r-- 1 root root 1315485 Nov 21 05:06 cp-9.ckpt.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root    1634 Nov 21 05:06 cp-9.ckpt.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytwEZJHjHR1b",
        "outputId": "c95e7f02-bb84-436e-a8b6-9876cebb67e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "latest = tf.train.latest_checkpoint(os.path.dirname(\"checkpoints/\"))\n",
        "print(latest)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoints/cp-11.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKe136ej359z"
      },
      "source": [
        "## Evaluate on test data\n",
        "\n",
        "Note that the test_labels are **not** in one_hot encoding. We convert them to one-hot using the function\n",
        "```\n",
        "tf.one_hot\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9pqSbriuiXb"
      },
      "source": [
        "#@title\n",
        "test_labels_one_hot=tf.one_hot(test_labels.flatten(),depth=10)\n",
        "model.evaluate(test_data,test_labels_one_hot)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}