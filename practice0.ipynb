{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "practice1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hikmatfarhat-ndu/NN-online/blob/main/practice0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pRwpeuRdCPG"
      },
      "source": [
        "# Practice 1\n",
        "\n",
        "In this  exercise we __modify__ the feedforward neural network we used  to recognize handwrittne digits (the MNIST data).  The modification involves the activation function for the intermediate layers. Instead of hardcoding them as we did before we supply them as parameters. \n",
        "\n",
        "For example if we have 3 layers with sigmoid for the intermediate and softmax for the last layer we supply the activations as a list of pair of functions. Each pair refers to the activation and its derivative.\n",
        " \n",
        "```\n",
        "activations=[(sigmoid,dsigmoid),(sigmoid,dsigmoid),(softmax,None)]\n",
        "\n",
        "```\n",
        "We also use another dataset: \"Iris\" dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AsZFi1WdCPI"
      },
      "source": [
        "### Packages\n",
        "\n",
        "The data set is very small so there is no need for  __cupy__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IE6Iu3NdCPL"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zKPdY6_7lyx"
      },
      "source": [
        "### Download data from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "YV6aY05E2G6M",
        "outputId": "c9346d2b-bd1b-4e4b-c170-aabc64106ef0"
      },
      "source": [
        "from google.colab import files\n",
        "file=files.upload()\n",
        "!mkdir /root/.kaggle\n",
        "!mv kaggle.json  /root/.kaggle\n",
        "!kaggle datasets download -d uciml/iris\n",
        "!unzip iris.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-238f2c29-83e1-4f35-bede-e2f7861e5b8b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-238f2c29-83e1-4f35-bede-e2f7861e5b8b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading iris.zip to /content\n",
            "  0% 0.00/3.60k [00:00<?, ?B/s]\n",
            "100% 3.60k/3.60k [00:00<00:00, 5.91MB/s]\n",
            "Archive:  iris.zip\n",
            "  inflating: Iris.csv                \n",
            "  inflating: database.sqlite         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_hbYpE37o3y"
      },
      "source": [
        "### Read the data using pandas\n",
        "\n",
        "After reading the data we drop the first column which contains a sequential id. We also shuffle the data using the sklearn shuffle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzfSXGLQ2nYa"
      },
      "source": [
        "df=pd.read_csv(\"Iris.csv\")\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPxIFXD976xg"
      },
      "source": [
        "Inspect the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7ZpXNzZ2tbq"
      },
      "source": [
        "df=df.drop('Id',axis=1)\n",
        "df = shuffle(df)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rsjI9nL78o6"
      },
      "source": [
        "We use sklearn LabelBinarizer to convert the names of the species to one_hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7yZUFd82xVk"
      },
      "source": [
        "species_lb = LabelBinarizer()\n",
        "labels = species_lb.fit_transform(df.Species.values)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meN0d5a28Ee-"
      },
      "source": [
        "Retrieve the features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9E7k-hN3bIp"
      },
      "source": [
        "features = df[df.columns[0:4]].values"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-ZOXTe28HeS"
      },
      "source": [
        "Split data into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPJCTQxV4uFm"
      },
      "source": [
        "x_train=features[0:120]\n",
        "x_test=features[120:150]\n",
        "y_train=labels[0:120]\n",
        "y_test=labels[120:150]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdhVYpgYdCP7"
      },
      "source": [
        "### Activation Functions\n",
        "\n",
        "Typically in such a setting the activation function for the inner layers could be sigmoid, relu,... and the activation for the last layer would be softmax which is a generalization of the sigmoid for multiclass inputs. Let $C$ be the set of classes and $c_1\\in C$ a given class the probability of $c_1$ becomes (where $z_i$ is the logit corrsponding to class $i$)\n",
        "\\begin{align*}\n",
        "softmax=\\frac{e^{z_1}}{\\sum_i e^{z_i}}\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLYWfHridCP-"
      },
      "source": [
        "def sigmoid(x):\n",
        "    s = 1/(1+np.exp(-x))\n",
        "    return s\n",
        "def softmax(x):\n",
        "    return np.exp(x)/np.sum(np.exp(x),axis=-1).reshape(x.shape[0],1)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qybJKP9mLyQB"
      },
      "source": [
        "## Derivative of the sigmoid\n",
        "\n",
        "The derivative of the sigmoid with respect to its parameter is easily obtained\n",
        "\\begin{align*}\n",
        "\\frac{\\partial\\sigma(z)}{\\partial z}&=\\frac{1}{\\partial z}\\frac{1}{1+e^{-z}}\\\\\n",
        "                                    &=\\frac{e^{-z}}{(1+e^{-z})^2}\\\\\n",
        "                                    &=\\frac{1}{1+e^{-z}}\\cdot \\frac{e^{-z}}{1+e^{-z}}\\\\\n",
        "                                    &=\\sigma(z)(1-\\sigma(z))\n",
        "\\end{align*}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isb8YcLoNL0l"
      },
      "source": [
        "#derivative of the sigmoid\n",
        "def dsigmoid(x):\n",
        "  return sigmoid(x)*(1-sigmoid(x))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR4gi1H-dCQn"
      },
      "source": [
        "The usual cross Entropy cost. Unlike the evaluate function both the \"true\" labels and the output of our model are in one-hot encoding.\n",
        "__NOTE__: the call to forward_propagation was changed to take an extra parameter: activations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA_ge60UdCQq"
      },
      "source": [
        "def compute_cost(X,Y,b,w,activations):\n",
        "    \n",
        "    m = Y.shape[0] # number of example\n",
        "\n",
        "    # Compute the cross-entropy cost\n",
        "    As,_=forward_propagation(X,b,w,activations)\n",
        "    # recall that As contains the \"output\" of all layers\n",
        "    # including the input As[0] and the final output As[-1]\n",
        "    output=As[-1]\n",
        "    logprobs = np.log(output)*Y\n",
        "    cost = -np.sum(logprobs)/m\n",
        "\n",
        "    count=0\n",
        "    for i in range(output.shape[0]):\n",
        "        if (np.argmax(output[i,:])==np.argmax(Y[i,:])):\n",
        "            count=count+1\n",
        "\n",
        "    \n",
        "    cost = np.squeeze(cost)     # makes sure cost is the dimension we expect. \n",
        "                                # E.g., turns [[17]] into 17 \n",
        "    \n",
        "    return cost,count\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQbNBETTdCQ0"
      },
      "source": [
        "The weights are initialized randomly and the biases are initially set to zero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU6wZ7Q_dCQ2"
      },
      "source": [
        "def initialize_parameters(width):    \n",
        "    weights=[]\n",
        "    biases=[]\n",
        "    for i in range(len(width)-1):\n",
        "        w=np.random.randn(width[i],width[i+1])\n",
        "        b=np.zeros((width[i+1],))\n",
        "        weights.append(w)\n",
        "        biases.append(b)\n",
        "\n",
        "    return biases,weights\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOMuTirBdCQ_"
      },
      "source": [
        "### __NEEDS CHANGE__: forward_propagation\n",
        "Forward propagation over all the layers but also retain the intermediate results.\n",
        "1. takes an extra parameter: list of activation functions\n",
        "1. use the proper activation for each layer\n",
        "1. returns logits Z in addition to A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZy75zCkdCRB"
      },
      "source": [
        "def forward_propagation(X,biases,weights,activations):\n",
        "    a=X\n",
        "    As=[X]\n",
        "    Z=[X]\n",
        "    para=zip(weights,biases,activations)\n",
        "    for i,(w,b,act) in enumerate(para):\n",
        "       z=np.dot(a,w)+b\n",
        "       ### REPLACE the calls with activations function from\n",
        "       ### activation list. Remember it is a list of tuples(act,derivative)\n",
        "       a=act[0](z)\n",
        "       #if i==len(biases)-1:\n",
        "         \n",
        "       #  a=softmax(z)\n",
        "       #else:\n",
        "       #  a=sigmoid(z)\n",
        "       #########################################################\n",
        "       As.append(a)\n",
        "       Z.append(z)\n",
        "    return As,Z"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6cM8jih2MHF"
      },
      "source": [
        "## Backpropagation\n",
        "\n",
        "Note how the gradient of a given layer depends on the gradient of the __next__ layer. This means that when computing the gradients we start from the __last__ layer and move __backwards__.\n",
        "\\begin{align*}\n",
        "\\Delta^l_{mn}&=\\sum_k \\Delta^{l+1}_{mk}W^l_{nk}\\theta^l_{mn}\\\\\n",
        "dW_{ij}&=\\frac{1}{m}\\sum_m\\Delta^{l+1}_{mj}A^l_{mi}\\\\\n",
        "dB_{j}&=\\frac{1}{m}\\sum_m\\Delta^{l+1}_{mj}\n",
        "\\end{align*}\n",
        "\n",
        "Or in matrix notation\n",
        "\\begin{align*}\n",
        "\\Delta^l&=\\Delta^{l+1}\\cdot (W^l)^T\\theta^l\\\\\n",
        "dW^l&=\\frac{1}{m}(A^l)^T\\cdot \\Delta^{l+1}\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA1hvYoKWfOy"
      },
      "source": [
        "### __NEEDS CHANGE__: Backpropagation\n",
        "\n",
        "theta depends on the activation of the layer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYzG_NTYdCRL"
      },
      "source": [
        "def backward_propagation(X,Y,biases,weights,activations):\n",
        "    \n",
        "    As,Z=forward_propagation(X,biases,weights,activations)\n",
        "    m = X.shape[0]\n",
        "    \n",
        "    nlayers=len(biases)\n",
        "    # Loss of the last layer\n",
        "    dz=As[nlayers]-Y\n",
        "\n",
        "    gradb=[]\n",
        "    gradw=[]\n",
        "    #iterator backwards from the last layer\n",
        "    for i in range(nlayers-1,-1,-1):\n",
        "        db=np.sum(dz,axis=0,keepdims=True)/m\n",
        "        dw=np.dot(As[i].T,dz)/m\n",
        "        # prepare the computation for the\n",
        "        # NEXT iteration. If i=0 there is no\n",
        "        # next iteration.\n",
        "        if i!=0:\n",
        "        ### REPLACE with the derivative of the activation\n",
        "          theta=activations[i-1][1](Z[i])\n",
        "        #################################################\n",
        "          dz=np.dot(dz,weights[i].T)*theta\n",
        "        gradb.insert(0,db)\n",
        "        gradw.insert(0,dw)\n",
        "    \n",
        "    return gradb,gradw"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-9o_pyWdCRY"
      },
      "source": [
        "def update_parameters(biases,weights, gradb,gradw, learning_rate):\n",
        "    for i in range(len(biases)):\n",
        "        weights[i]=weights[i]-learning_rate*gradw[i]\n",
        "        biases[i]=biases[i]-learning_rate*gradb[i]\n",
        "\n",
        "    return biases,weights"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ86sIZGngbZ"
      },
      "source": [
        "### Stochastic Gradient Descent\n",
        "\n",
        "We deal with the input data in __random batches__. We select a set of random indices and take a slice from X and Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45Uo0DJvdCRr"
      },
      "source": [
        "def GD(X, Y, test_data,width,activations,batch_size,num_iterations, learning_rate,print_cost=False):\n",
        "\n",
        "    biases,weights=initialize_parameters(width)\n",
        "    \n",
        "    for i in range(0, num_iterations):\n",
        "        cost,count = compute_cost(X,Y,biases,weights,activations)\n",
        "        for k in range(0,X.shape[0],batch_size):\n",
        "            ## We CANNOT use np.random.shuffle because\n",
        "            ## it would randomize x and y DIFFERENTLY\n",
        "            ## instead get a set of random  indices\n",
        "            ## and use the SAME indices for x and y\n",
        "            idx=[random.randint(0,Y.shape[0]-1) for s in range(batch_size)]\n",
        "            yb=Y[idx,:]\n",
        "            xb=X[idx,:]\n",
        "            gradb,gradw=backward_propagation(xb,yb,biases,weights,activations)\n",
        "            biases,weights=update_parameters(biases,weights,gradb,gradw,learning_rate)    \n",
        "\n",
        "        if i%20 ==0 : \n",
        "            #count_test=evaluate(test_data,test_labels,biases,weights)\n",
        "            count=count/Y.shape[0]\n",
        "            print (\"Epoch {}: cost={:.2f},train accuracy={:.2f}\".format(i,cost,count))\n",
        "                \n",
        "    return biases,weights"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfalzdA4n2e7"
      },
      "source": [
        "#### Run SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jwvx3a785L8t",
        "outputId": "153dd64a-5cec-40c1-d498-6216d779fa79"
      },
      "source": [
        "n_x=x_train.shape[1]\n",
        "n_y=y_train.shape[1]\n",
        "width=[n_x,16,8,n_y]\n",
        "#### define the list of tuples (activation,derivative of activation)\n",
        "##activations=None\n",
        "activations=[(sigmoid,dsigmoid),(sigmoid,dsigmoid),(softmax,None)]\n",
        "####\n",
        "biases,weights= GD(x_train,y_train,x_test,width,activations,batch_size=8,learning_rate=0.05,\n",
        "                num_iterations =100, print_cost=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: cost=1.14,train accuracy=0.33\n",
            "Epoch 20: cost=0.43,train accuracy=0.97\n",
            "Epoch 40: cost=0.30,train accuracy=0.93\n",
            "Epoch 60: cost=0.21,train accuracy=0.95\n",
            "Epoch 80: cost=0.15,train accuracy=0.99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNS_L9N5dCQY"
      },
      "source": [
        "Returns the number of correct predictions. Note that the output of our model is in one-hot encoding so it has 10 columns and N rows where N is the number of data points whereas test_labels is NOT in one-hot encoding so it has a single column and N rows. For a given row i, argmax returns the column index which has the largest value, i.e. the largest likelyhood\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhUZc1rDdCQa"
      },
      "source": [
        "def evaluate(test_data,test_labels,biases,weights,activations):\n",
        "    As,_=forward_propagation(test_data,biases,weights,activations)\n",
        "    output=As[-1]\n",
        "    count=0\n",
        "    #the output is in one-hot encoding so it has 10 rows\n",
        "    # and number of data columns where as test_tables \n",
        "    # is NOT in one-hot encoding so it has a single row\n",
        "    for i in range(output.shape[0]):\n",
        "        if np.argmax(output[i,:])==np.argmax(test_labels[i,:]):\n",
        "            count=count+1\n",
        "    return count/test_labels.shape[0]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zGkU74R37wg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94cf74eb-4e52-4852-8233-d5842170d751"
      },
      "source": [
        "evaluate(x_test,y_test,biases,weights,activations)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}